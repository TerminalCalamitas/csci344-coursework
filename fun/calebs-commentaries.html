<!DOCTYPE>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Caleb's Commentaries</title>
    <link rel="stylesheet" href="styles.css">
    <link rel="icon" type="image" href="../favicon.png">
  </head>
    <header>
      <h1>Caleb's Commentaries</h1>
      <p>This is a page for me to ramble about various topics.</p>
    </header>
  <body>
    <section class="sidebar">
      <h2>Table of Contents</h2>
      <ul>
        <li><b><a href="../index.html">Back Home</a></b></li>
        <li><a href="#topic1">How do LLM's work?</a></li>
        <li><a href="#topic2">Applications for AI in Education</a></li>
      </ul>
    </section>

    <section class="topic" id="topic1">
      <h2><b>How do LLM's work?</b></h2>
      <p>
        LLM's are very complicated math models that use given data to make predictions about what is most likely to come next, <b>they are not intelligent and cannot understand or make decisions</b>.
        <br>Currently companies have found that by giveing more data to the LLMs during the training process, the LLMs are able to make more accurate predictions since they have more information about how people usually talk.
        When the LLM is given an input prompt, it turns that prompt into a series of numbers called tokens that represent the text. 
        The LLM then uses a series of matrix multiplications operations on the input tokens to determine the token that is most likely to come next. 
        Unlike what is commonly believed, none of the LLMs are able to understand the input or the data it was trained on. 
        While it is possible to use LLMs to generate the materials that the LLM was trained on, <b>the model is never able to direcly copy sections from the input data</b>.
      </p>
    </section>

    <section class="topic" id="topic2">
      <h2><b>Applications for AI in Education</b></h2>
      <p>&emsp; I believe that AI should be viewed as an academic tool rather than something harmful that needs
to be avoided. While I wasn’t alive when the web started becoming popular I believe that schools and
educators would have had some of the same concerns about the internet as people have about it today.
The internet, just like AI has the possibillity to hinder learning if the student just uses it for plaigerism
rather than engaging with the matierial they are using. Just as the internet has become a core part of
modern education, I belive that if students are instructed in the proper way to use AI, <b>it has the potential
to be just as helpful if not more helpful than the internet for education.</b><br><br>
&emsp; It is very simple to get an LLM to respond in a certain manner and so while information may be
presented by teachers or websites in a specific way, if someone is having trouble understanding, they
can ask AI to explain the material in whatever manner is <b>most helpful to them.</b> This point does bring up
the problem of students using AI to get out of learning by just copying the output from LLM models.
This is another situation where there are many similarities to when the internet was new. If there are not
expectations and appropriate limitations put in place then students will take the easiest way to get
something done.<br><br>
&emsp; I have used AI in some of my classes before and I believe it helped me better understand what I
was doing and what I should be doing. For example, when running C programs I often got the error
`Segmentation Fault` which doesn’t give much helpful information about what I did wrong. By asking
an LLM questions during my debugging process I was better able to understand what the problem was
as well as being able to fix the problem faster. <b>As a conclusion, I believe that while AI can be used
negatively in a student’s education, universities should adapt their teaching to encourage a healthy
relationship between students and AI.</b>
      </p>
    </section>
  </body>
</html>

